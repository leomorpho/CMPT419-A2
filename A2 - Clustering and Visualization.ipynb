{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and Visualization of Phoebe dataset\n",
    "\n",
    "## Components\n",
    "* Create dataset with every row linked to the image it was generated from\n",
    "    * Will need to extract images from videos like this:\n",
    "    `ffmpeg -ss 00:23:00 -i video.mp4 -frames:v 1 out_time.jpg`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload  # Not needed in Python 2\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "\n",
    "import os\n",
    "DATASET_FILE = \"Phoebe_dataset4.zip\"\n",
    "full_path = os.path.abspath(DATASET_FILE)\n",
    "if not os.path.exists(full_path):\n",
    "    !unzip $DATASET_FILE;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load datasets\n",
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import os, os.path\n",
    "from typing import List, Dict, Union, Any\n",
    "import csv\n",
    "import uuid\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "# Paths\n",
    "PATH_DATASET = \"Phoebe_dataset4\"\n",
    "PATH_AU_INTENSITY = \"single_person_au_intensity\"\n",
    "PATH_AU_PRESENCE = \"single_person_au_presence\"\n",
    "PATH_TRAIN = \"train\"\n",
    "PATH_TEST = \"test\"\n",
    "PATH_TRAINING_VIDEOS = PATH_DATASET + \"/videos/train\"\n",
    "PATH_PROCESSED_IMAGES = PATH_DATASET + \"/processed_images\"\n",
    "PATH_TRAINING_CSV = f\"./{PATH_DATASET}/{PATH_AU_INTENSITY}/{PATH_TRAIN}/\"\n",
    "\n",
    "# General\n",
    "EXT_MP4 = \"mp4\"\n",
    "\n",
    "# Stores\n",
    "IMAGE_STORE = {}\n",
    "\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "if not os.path.isdir(PATH_PROCESSED_IMAGES):\n",
    "    os.mkdir(PATH_PROCESSED_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename: str) -> List[Union[str, float]]:\n",
    "    \"\"\"Load dataset for a single csv/video pair.\n",
    "    \n",
    "    :param filename: name of video and csv without an extension.\n",
    "    \n",
    "    :return: result dataset for csv/video pair.\n",
    "    \"\"\"\n",
    "    # Load csv with python library so that first column may be removed.\n",
    "    print(filename)\n",
    "    raw_data = []\n",
    "    with open(filename, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        \n",
    "        for index, row in enumerate(reader):\n",
    "            if index == 0:\n",
    "                row = [x.strip() for x in row]\n",
    "                # Rename column row\n",
    "                row[0] = \"frame\"\n",
    "                \n",
    "                # Create a new column to save filename the row came from.\n",
    "                # This is used to extract image when needed (filename + frame are needed)\n",
    "                row.insert(0, \"filename\")\n",
    "                \n",
    "            elif row[0] != \"\":\n",
    "                # Create an image for every row and add to dictionnary {id: path}\n",
    "                filename_without_ext: str = re.findall(r\"[0-9]+\", filename)[-1]\n",
    "                row.insert(0, filename_without_ext)\n",
    "            raw_data.append(row)\n",
    "    \n",
    "    return raw_data\n",
    "\n",
    "def create_full_dataset(training_files) -> List[Union[str, float]]:\n",
    "    \"\"\"Load dataset for every csv/video pair.\n",
    "    \n",
    "    :param training_files: list of csv files.\n",
    "    \n",
    "    :return: full dataset results\n",
    "    \"\"\"\n",
    "    assert(isinstance(training_files, list)) \n",
    "    full_dataset = []\n",
    "    for file in training_files:\n",
    "        dataset = load_dataset(file)\n",
    "        if len(full_dataset) == 0:\n",
    "            full_dataset = dataset\n",
    "        else:\n",
    "            full_dataset.extend(dataset[1:])\n",
    "    return full_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get image\n",
    "If image has not been extracted for given id, extract it from corresponding video. This is made easy because the matrix stores the video name (without the extension) and the frame number.\n",
    "\n",
    "Pass the entire row of data to the `extract_image_for_frame` function in order to get the correct frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "import datetime\n",
    "\n",
    "# %%capture\n",
    "def extract_image_for_frame(image_path: str, video_name: str, frame: str):\n",
    "    \"\"\"Extracts a frame from a video given a timestamp in seconds.\n",
    "    \n",
    "    :param orig_filename: name of video for which timestamp applies\n",
    "    :param row_id: id of row and image\n",
    "    \n",
    "    :return: name of the image without its extension.\n",
    "    \"\"\"\n",
    "\n",
    "    video_filepath = PATH_TRAINING_VIDEOS + f\"/{video_name}.{EXT_MP4}\"\n",
    "    \n",
    "    # Data was sampled at about 30fps. Get time at which it is in the video\n",
    "    time_in_seconds = (1/30) * frame\n",
    "    time_datetime = datetime.timedelta(seconds=time_in_seconds)\n",
    "    \n",
    "    log.debug(f\"Extracting frame at time {time_datetime} from path {video_filepath}\")        \n",
    "    # command = f\"ffmpeg -i {video_filepath} -r 30 {image_path}.jpg\"\n",
    "    \n",
    "    command = f\"ffmpeg -i {video_filepath} -ss {time_datetime} -vframes 1 {image_path}.jpg -n\"\n",
    "    log.debug(f\"Running command: {command}\")\n",
    "\n",
    "    print(f\"### \")\n",
    "    !$command;\n",
    "\n",
    "    \n",
    "def show_image(row: List[Any]):\n",
    "    \"\"\"\n",
    "    :param row: a row of data\n",
    "    \"\"\"\n",
    "    log.debug(f\"### Getting image for row: {row}\")\n",
    "    \n",
    "    video_name = int(row[0])\n",
    "    frame = int(row[0])\n",
    "    image_name = f\"{video_name:03}{frame:03}\"\n",
    "    image_path = PATH_PROCESSED_IMAGES + image_name\n",
    "    if not os.path.exists(image_path):\n",
    "        extract_image_for_frame(image_path, video_name, frame)\n",
    "        \n",
    "    try:\n",
    "        image = Image(filename=f'{image_path}.jpg')\n",
    "        display(image)\n",
    "    except IOError as e:\n",
    "        print(e)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run dataset preparation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Phoebe_dataset4/single_person_au_intensity/train/6.csv', './Phoebe_dataset4/single_person_au_intensity/train/40.csv']\n",
      "./Phoebe_dataset4/single_person_au_intensity/train/43.csv\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "training_files: List[str] = [f\"{PATH_TRAINING_CSV}{name}\" for \n",
    "                             name in os.listdir(f\"{PATH_TRAINING_CSV}\") if \n",
    "                             name[-4:] == \".csv\"]\n",
    "\n",
    "print(training_files[0:2])\n",
    "# Load datasets\n",
    "full_dataset = create_full_dataset(training_files[4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "[['filename', 'frame', 'face_id', 'confidence', 'success', 'AU01_r', 'AU02_r', 'AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r', 'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r'], ['43', '0', '0', '0.98', '1', '0.09', '0.0', '0.65', '0.07', '1.61', '1.69', '0.0', '1.19', '1.6', '0.51', '0.0', '1.9', '0.0', '0.0', '0.59', '0.56', '0.0'], ['43', '1', '0', '0.98', '1', '0.07', '0.21', '0.52', '0.02', '1.09', '1.71', '0.0', '0.71', '1.35', '0.23', '0.0', '1.4', '0.0', '0.0', '0.38', '0.2', '0.0'], ['43', '2', '0', '0.98', '1', '0.07', '0.28', '0.51', '0.0', '0.89', '1.52', '0.0', '0.58', '1.23', '0.11', '0.0', '1.01', '0.0', '0.0', '0.21', '0.02', '0.11'], ['43', '3', '0', '0.98', '1', '0.07', '0.28', '0.41', '0.0', '0.84', '1.43', '0.01', '0.62', '1.2', '0.08', '0.0', '1.0', '0.0', '0.0', '0.47', '0.41', '0.22']]\n"
     ]
    }
   ],
   "source": [
    "print(len(full_dataset))\n",
    "print(full_dataset[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images in Image datastore are \"fileid_frame\"\n",
    "show_image(full_dataset[1])\n",
    "print(full_dataset[0])\n",
    "print(full_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preprocess and cleanup data\n",
    "* Remove rows with confidence < 80\n",
    "* Remove rows with empty value(s)\n",
    "\n",
    "### Compare ML algorithms for\n",
    "* Scale data between 0 and 1, and unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = numpy.array(full_dataset)\n",
    "\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Gausian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GMM' from 'sklearn.mixture' (/Users/leo/workspace/cmpt419/CMPT419-A2/venv/lib/python3.7/site-packages/sklearn/mixture/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-578c7143d1de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGMM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GMM' from 'sklearn.mixture' (/Users/leo/workspace/cmpt419/CMPT419-A2/venv/lib/python3.7/site-packages/sklearn/mixture/__init__.py)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.mixture import GMM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
